 
# 1. Create a matrix

```{r}
set.seed(5)
random_data_1 <- sample(1:100, 36)
random_data_2 <- sample(500: 600, 36)
mat_A <- matrix(random_data_1, 6, 6)
mat_B <- matrix(random_data_2, 6, 6)
mat_A
mat_B
```
### a. find range of matrices A and B
```{r}
range(mat_A)
range(mat_B)
```
### b. find max of each row from matrices A and B
```{r}
for(row in 1:nrow(mat_A)){
  print(max(mat_A[row,]))
  print(max(mat_B[row,]))
}
```
### c. find diagnol value of matrices A and B
```{r}
diag_A <- diag(mat_A)
diag_A
diag_B <- diag(mat_B)
diag_B
```
### d. multiply matrix A and B
```{r}
mat_A * mat_B
```

### e. replace 4th row of matrix A with diagnol value of matrix B
```{r}
mat_A[4, 1:6] <- diag_B
mat_A
```
### f. multiply matrix A and B, assign to x
```{r}
x <- mat_A %*% mat_B
x
```
### g. divide matrix A and B
```{r}
s_mat_B = solve(mat_B)
mat_A %*% s_mat_B
```

# 2. Create a data frame
```{r}
set.seed(5)
df <- data.frame(
  X.First.name=c('John', 'George', 'Kay', 'Edel', 'Elesis', 'Elesword', 'Ganyu', 'Mike', 'Lass', 'Seighart'),
  X.Second.name=c('Cena', 'Bush', 'Vidius', 'Amori', 'Frencis', 'Frencis', 'Lapis', 'Tyson', 'Lang', 'Highlander'),
  Age=sample(c(18:50), 10),
  Occupation=rep("knight", 10),
  Place="Teyvet",
  X.Random.numbers=sample(1:10, 10)
  )
df
#df$X.First.name. <- c('John', 'Bush', 'Kay', 'Edel', 'Elesis', 'Elesword', 'Ganyu', 'Mike', 'Lass', 'Seighart')
```

### g. extract last column
```{r}
last_col <- df[ncol(df)]
last_col
```
### h. find sum, mean and length
```{r}
sum(last_col)
mean(last_col)
length(last_col)
```
# 3. Create a file

ref: https://www.khmertimeskh.com/50801787/covid-19-cambodia-relaxes-restrictions-singapore-indonesia-promotes-vaccination-plans/

### a. read the file
```{r}
library(readr)
library(dplyr)
library(tidytext)
library(sentimentr)
khmer_news <- read_file(paste(getwd(), '/khmer_news.txt', sep=""))
khmer_news
```
### b. perform tokenization and count words
```{r}
data <- data.frame(Text=khmer_news) %>%
  unnest_tokens(Info, Text) %>%
  count(Info, sort=TRUE)
data
```
### c. replace most repeated word with 'KIT'
```{r}
most_repeated = data$Info[1]
replaced_text = sub(most_repeated, 'KIT', khmer_news)
replaced_text
```
### d. perform sentiment analysis
```{r}
library(sentimentr)
sen1 = sentiment(khmer_news) # To know number of sentences and words(Sentiment at the sentence level)
print(sen1)
sen2 = sentiment_by(khmer_news) # total number of words 
print(sen2)
sen3 = get_sentences(khmer_news) # To display the sentences
print(sen3)
sen4<- emotion(khmer_news) # Emotion at the sentence level
print(sen4)
sen5<- emotion_by(khmer_news) # Aggregated emotion by group(s)
print(sen5)
sen6<- profanity(khmer_news) # Profanity at the sentence level
print(sen6)
sen7<- profanity_by(khmer_news) # Aggregated profanity by group(s)
sen7
```
### e. plot the graph
```{r}
library(ggplot2)
words_graph <- data.frame(Text=khmer_news)%>% 
  unnest_tokens(Info, Text) %>%
  count(Info, sort=TRUE)  %>% 
  ggplot(aes(n, Info)) + geom_col() +
  xlab("Number of words") +
  ylab("List of word") +
  ggtitle("Text mining using R") +
  theme(axis.title.x=element_text(size=10, color="blue", face="bold", margin=margin(t=20)),
        axis.title.y=element_text(size=10, color="red", face="bold", margin=margin(r=20)),
        plot.title=element_text(size=25, color="yellow", face="bold", margin=margin(b=20)))
words_graph
ggsave(filename="words_count.png", unit="cm", width=100, height=100)
```

# 4. Find the assigned Dataset from the list below and perform the following

### a. import data
```{r}
organic_data_set <- data.frame(read.csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/presidential-candidate-favorables-2019/favorability_polls_rv_2019.csv"))
head(organic_data_set)
```

### a. clean data
```{r}
organic_data_set <- imputeMissings::impute(organic_data_set)
organic_data_set
```

### b. find the x and y variables

x: for pollster
y: for number of favorable

I'm trying to find out which pollster has the highest number of favorable count when hosting the poll
```{r}
library(ggplot2)
filtered_data <- data.frame(organic_data_set$pollster, organic_data_set$favorable)
head(filtered_data)
most_fav_pollster_graph <- ggplot(filtered_data, aes(x=filtered_data$organic_data_set.pollster, y=filtered_data$organic_data_set.favorable))
```

### c. plot graph using geom_col()
```{r}
most_fav_pollster_graph <- most_fav_pollster_graph + geom_col(mapping=aes(x=filtered_data$organic_data_set.pollster, y=filtered_data$organic_data_set.favorable))

most_fav_pollster_graph <- most_fav_pollster_graph + theme_minimal()
most_fav_pollster_graph
```

### e.

```{r}
most_fav_pollster_graph <- most_fav_pollster_graph + labs(title="Most favorable pollster", x="Pollster", y="Favorable count")

most_fav_pollster_graph <- most_fav_pollster_graph + theme(
  axis.title =  element_text(size = 10, face = "bold"),
  axis.title.x = element_text(margin = margin(t=20,r=0,b=0,l=0), colour = "green"),
  axis.title.y = element_text(margin = margin(t=0,r=20,b=0,l=0), colour = "yellow"),
  plot.title = element_text(size = 25, margin = margin(t=0,r=0,b=25,l=0), face = "bold", hjust=0.5, colour = "blue")
) + geom_smooth(method ="lm") + coord_cartesian() + scale_color_gradient()
most_fav_pollster_graph
ggsave(filename="most_fav_pollster_graph.png", unit="cm", width=50, height=15)
```
### d. perform facet
```{r}
most_fav_pollster_graph <- most_fav_pollster_graph + facet_grid(. ~ filtered_data$organic_data_set.pollster)
most_fav_pollster_graph
ggsave(filename="facet.png", unit="cm", width=100, height=20)
```

### 